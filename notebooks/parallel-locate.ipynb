{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelized Feature Location using IPython Parallel\n",
    "\n",
    "Feature-finding can easily be parallelized: each frame an independent task, and the tasks can be divided among the available CPUs. [IPython parallel](https://github.com/ipython/ipyparallel) makes this very straightforward.\n",
    "\n",
    "## Intsall ipyparallel\n",
    "\n",
    "As of IPython 6.2 (November 2017), IPython parallel is a separate package. You may need to install it at the command prompt using `pip install ipyparallel` or `conda install ipyparallel`.\n",
    "\n",
    "It is simplest to start a cluster on the CPUs of the local machine. In order to start a cluster, you will need to go to a Terminal and type:\n",
    "```\n",
    "ipcluster start -n 4\n",
    "```\n",
    "\n",
    "The number 4 should be replaced by the number of available CPUs. Now you are running a cluster -- it's that easy. More information on IPython parallel is available in [the IPython parallel documentation](http://ipyparallel.readthedocs.io/en/latest/intro.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyparallel import Client\n",
    "client = Client()\n",
    "view = client.load_balanced_view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are four cores available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DirectView [0, 1, 2, 3]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a little magic, ``%%px``, to import trackpy on all cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import trackpy as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the normal setup now, import trackpy normally and loading frames to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pims\n",
    "import trackpy as tp\n",
    "\n",
    "@pims.pipeline\n",
    "def gray(image):\n",
    "    return image[:, :, 0]\n",
    "\n",
    "frames = gray(pims.ImageSequence('../sample_data/bulk_water/*.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function from ``locate`` with all the parameters specified, so the function's only argument is the image to be analyzed. We can map this function directly onto our collection of images. (This is a called \"currying\" a function, hence the choice of name.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "curried_locate = lambda image: tp.locate(image, 13, invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncMapResult: <lambda>>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view.map(curried_locate, frames[:4])  # Optionally, prime each engine: make it set up numba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the time it takes to locate features in the first ten images with and without parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  32/32 tasks finished after    0 s\n",
      "done\n",
      "817 ms ± 48.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "amr = view.map_async(curried_locate, frames[:32])\n",
    "amr.wait_interactive()\n",
    "results = amr.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.29 s ± 45.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "serial_result = list(map(curried_locate, frames[:32]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speedup is not very impressive in this case because each frame is relatively easy to compute, and parallel processing introduces some overhead (for example, the parent process still has to read each frame and send it to a worker). But for more challenging uses of `locate` this will greatly speed up processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trackpy-examples",
   "language": "python",
   "name": "trackpy-examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
